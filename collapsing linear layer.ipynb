{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccbe4d86e9fe487e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:28:53.336543300Z",
     "start_time": "2024-03-21T07:28:53.030976400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tenseal as ts\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f16e7deb303685",
   "metadata": {},
   "source": [
    "## FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78c75c5d149d3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:28:53.381491400Z",
     "start_time": "2024-03-21T07:28:53.287445400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 11255510.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 191490.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3523271.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 5707712.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(22)\n",
    "\n",
    "train_data = datasets.FashionMNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eeba3f055ae57b",
   "metadata": {},
   "source": [
    "## CryptoNets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:28:53.641277800Z",
     "start_time": "2024-03-21T07:28:53.569577500Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CryptoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CryptoNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 2, 1)\n",
    "        self.pool1 = nn.AvgPool2d(3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, (2, 2), 0)\n",
    "        self.fc1 = nn.Linear(1250, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        nn.init.kaiming_normal_(self.conv2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # (64,20,13,13) 3380\n",
    "        x = x * x  # 使用平方激活函数\n",
    "        x = self.pool1(x) # (64,20,13,13) 3380\n",
    "        x = self.conv2(x) # (64,50,5,5) 1250\n",
    "        x = self.pool1(x) # (64,50,5,5) 1250\n",
    "        x = torch.flatten(x, 1) # 1250\n",
    "        x = self.fc1(x)\n",
    "        x = x * x  # 使用平方激活函数\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7425cdf9df9f4aa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:29:46.188644700Z",
     "start_time": "2024-03-21T07:28:53.584129Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.715167 \tCorrect: 45414 \tAccuracy: 75.690 \ttime: 10.508\n",
      "Epoch: 2 \tTraining Loss: 0.459788 \tCorrect: 50210 \tAccuracy: 83.683 \ttime: 10.573\n",
      "Epoch: 3 \tTraining Loss: 0.399890 \tCorrect: 51357 \tAccuracy: 85.595 \ttime: 10.314\n",
      "Epoch: 4 \tTraining Loss: 0.366117 \tCorrect: 52084 \tAccuracy: 86.807 \ttime: 10.475\n",
      "Epoch: 5 \tTraining Loss: 0.348206 \tCorrect: 52432 \tAccuracy: 87.387 \ttime: 10.230\n",
      "Epoch: 6 \tTraining Loss: 0.331562 \tCorrect: 52703 \tAccuracy: 87.838 \ttime: 10.422\n",
      "Epoch: 7 \tTraining Loss: 0.316892 \tCorrect: 52961 \tAccuracy: 88.268 \ttime: 10.276\n",
      "Epoch: 8 \tTraining Loss: 0.305246 \tCorrect: 53232 \tAccuracy: 88.720 \ttime: 10.359\n",
      "Epoch: 9 \tTraining Loss: 0.296608 \tCorrect: 53390 \tAccuracy: 88.983 \ttime: 10.353\n",
      "Epoch: 10 \tTraining Loss: 0.290693 \tCorrect: 53532 \tAccuracy: 89.220 \ttime: 10.445\n",
      "Epoch: 11 \tTraining Loss: 0.277052 \tCorrect: 53860 \tAccuracy: 89.767 \ttime: 10.401\n",
      "Epoch: 12 \tTraining Loss: 0.269662 \tCorrect: 53956 \tAccuracy: 89.927 \ttime: 10.567\n",
      "Epoch: 13 \tTraining Loss: 0.260698 \tCorrect: 54117 \tAccuracy: 90.195 \ttime: 10.391\n",
      "Epoch: 14 \tTraining Loss: 0.254858 \tCorrect: 54273 \tAccuracy: 90.455 \ttime: 10.331\n",
      "Epoch: 15 \tTraining Loss: 0.249679 \tCorrect: 54464 \tAccuracy: 90.773 \ttime: 10.376\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# cpu\n",
    "def train(model, train_loader, criterion, optimizer, n_epochs=30):\n",
    "    # 将模型设为训练模式\n",
    "    model.train()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        correct_new = 0\n",
    "        total_new = 0\n",
    "        \n",
    "        t1 = time()\n",
    "        for data, target in train_loader:\n",
    "            # 将梯度置零\n",
    "            optimizer.zero_grad()\n",
    "            # 前向传播\n",
    "            output = model(data)\n",
    "            # 计算损失\n",
    "            loss = criterion(output, target)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 更新权重\n",
    "            optimizer.step()\n",
    "            # 计算损失\n",
    "            train_loss += loss.item()\n",
    "            # 比较预测值和真实值\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_new += target.size(0)\n",
    "            correct_new += (predicted == target).sum().item()\n",
    "        t2 = time()\n",
    "\n",
    "        # 计算平均损失\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        acc_new = 100 * correct_new / total_new\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tCorrect: {} \\tAccuracy: {:.3f} \\ttime: {:.3f}'.format(epoch, train_loss, correct_new, acc_new, t2 - t1))\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    return model\n",
    "\n",
    "# 创建模型实例\n",
    "model = CryptoNet()\n",
    "# 定义损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# 训练模型\n",
    "model = train(model, train_loader, criterion, optimizer, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272cc4ceb39946af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:29:46.222522300Z",
     "start_time": "2024-03-21T07:29:46.191637Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存整个模型\n",
    "PATH = './model/MNIST_CryptoNet.pth'\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# 只保存模型权重\n",
    "PATH = './model/MNIST_WeightCryptoNet.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb1fd0693312fe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:29:47.871068800Z",
     "start_time": "2024-03-21T07:29:46.227508700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.334308\n",
      "\n",
      "Test Accuracy of 0: 84% (847/1000)\n",
      "Test Accuracy of 1: 97% (973/1000)\n",
      "Test Accuracy of 2: 77% (771/1000)\n",
      "Test Accuracy of 3: 87% (875/1000)\n",
      "Test Accuracy of 4: 89% (893/1000)\n",
      "Test Accuracy of 5: 97% (971/1000)\n",
      "Test Accuracy of 6: 65% (655/1000)\n",
      "Test Accuracy of 7: 94% (948/1000)\n",
      "Test Accuracy of 8: 96% (965/1000)\n",
      "Test Accuracy of 9: 95% (956/1000)\n",
      "\n",
      "Test Accuracy (Overall): 88% (8854/10000)\n",
      "test time= 1.324462652206421\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "def test(model, test_loader, criterion):\n",
    "    # 初始化测试损失\n",
    "    test_loss = 0.0\n",
    "    # 初始化每个类别的正确预测数\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    # 初始化每个类别的总数\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    # 将模型设为评估模式\n",
    "    model.eval()\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        \n",
    "        # 前向传播，得到模型输出\n",
    "        output = model(data)\n",
    "        # 计算损失\n",
    "        loss = criterion(output, target)\n",
    "        # 累积测试损失\n",
    "        test_loss += loss.item()\n",
    "        # 将输出概率转换为预测类别\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # 将预测与真实标签比较，得到每个样本是否预测正确的结果\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # 计算每个对象类别的测试准确率\n",
    "        for i in range(len(target)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # 计算平均测试损失\n",
    "    test_loss = test_loss/len(test_loader)\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "\n",
    "    for label in range(10):\n",
    "        print(\n",
    "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
    "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
    "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
    "    )\n",
    "\n",
    "# 加载模型\n",
    "PATH = './model/MNIST_CryptoNet.pth'\n",
    "model = torch.load(PATH)\n",
    "\n",
    "t1 = time()\n",
    "test(model.to('cpu'), test_loader, criterion)\n",
    "t2 = time()\n",
    "print(\"test time=\", t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31dc3cbc5c2dfb",
   "metadata": {},
   "source": [
    "## Collapsing linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c185d0d5a3a58bbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:29:48.078531400Z",
     "start_time": "2024-03-21T07:29:47.893974500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "引入本层的作用主要是将卷积层和线性层合二为一，在增加网络层数的情况下，减小同态加密运算的开销，折叠层的原理是所有线性操作的组合仍然是线性的\n",
    "'''\n",
    "\n",
    "model1 = torch.load('./model/MNIST_CryptoNet.pth')\n",
    "# 输入图片大小\n",
    "in_channels = 20\n",
    "h = 13\n",
    "w = h\n",
    "\n",
    "#卷积层参数\n",
    "out_channels = 50\n",
    "kernel = 5\n",
    "stride = 2\n",
    "\n",
    "#线性层参数\n",
    "in_features=int (out_channels * (((h - kernel) / 2) + 1)**2)\n",
    "out_features = 100\n",
    "\n",
    "#conv2 = torch.nn.Conv2d (in_channels, out_channels, kernel, stride)\n",
    "#fc1 = torch.nn.Linear (in_features, out_features)\n",
    "pool1 = nn.AvgPool2d(3, stride=1, padding=1)\n",
    "\n",
    "conv2 = model1.conv2\n",
    "fc1 = model1.fc1\n",
    "\n",
    "# 创建折叠层的偏置\n",
    "bias = fc1 (torch.flatten (pool1(conv2 (pool1(torch.zeros (1, in_channels, h, w))))))\n",
    "\n",
    "# 创建折叠层的权重\n",
    "n_pixels = in_channels * h * w \n",
    "pixel_batch = torch.eye (n_pixels).reshape (n_pixels, in_channels, h, w)\n",
    "weight = (fc1 (torch.flatten (pool1(conv2 (pool1(pixel_batch))), 1)) - bias).T\n",
    "\n",
    "# 创建折叠层\n",
    "fcnew = torch.nn.Linear (n_pixels, out_features)  \n",
    "\n",
    "# 复制权重和偏置\n",
    "with torch.no_grad():\n",
    "  _ = fcnew.weight.copy_ (weight)\n",
    "  _ = fcnew.bias.copy_ (bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffe37cf0712d1e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:29:48.114422500Z",
     "start_time": "2024-03-21T07:29:48.075474100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存折叠模型\n",
    "PATH = './model/MNIST_WeightCollapsed.pth'\n",
    "torch.save(model1.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7325f104baa8c355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:29:48.126390500Z",
     "start_time": "2024-03-21T07:29:48.093978500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CryptoNets和 fastCryptoNets压缩过后模型结构一样！\n",
    "class CollapsedCryptoNets(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CollapsedCryptoNets, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=2, padding=1)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.fcnew = nn.Linear(3380, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "        # \n",
    "        with torch.no_grad():\n",
    "          _ = self.fcnew.weight.copy_ (weight)\n",
    "          _ = self.fcnew.bias.copy_ (bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x * x  # 使用平方激活函数\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fcnew(x)\n",
    "        x = x * x  # 使用平方激活函数\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "#创建折叠模型\n",
    "model2 = CollapsedCryptoNets()\n",
    "\n",
    "# 折叠模型读取训练权重\n",
    "PATH = './model/MNIST_WeightCollapsed.pth'\n",
    "model2.load_state_dict(torch.load(PATH), strict=False)\n",
    "torch.save(model2, './model/MNIST_CollapsedNet.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c08b779079fa7",
   "metadata": {},
   "source": [
    "## Collapsed CryptoNets for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64208c2b03b7eb0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:29:49.447983800Z",
     "start_time": "2024-03-21T07:29:48.123400300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.334714\n",
      "\n",
      "Test Accuracy of 0: 84% (847/1000)\n",
      "Test Accuracy of 1: 97% (973/1000)\n",
      "Test Accuracy of 2: 77% (771/1000)\n",
      "Test Accuracy of 3: 87% (875/1000)\n",
      "Test Accuracy of 4: 89% (893/1000)\n",
      "Test Accuracy of 5: 97% (971/1000)\n",
      "Test Accuracy of 6: 65% (655/1000)\n",
      "Test Accuracy of 7: 94% (948/1000)\n",
      "Test Accuracy of 8: 96% (965/1000)\n",
      "Test Accuracy of 9: 95% (956/1000)\n",
      "\n",
      "Test Accuracy (Overall): 88% (8854/10000)\n",
      "test time= 1.2042276859283447\n"
     ]
    }
   ],
   "source": [
    "# cpu\n",
    "# 此处直接用collapsed CryptoNets的训练网络进行测试\n",
    "def test(model, test_loader, criterion):\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    # 将模型设为评估模式\n",
    "    model.eval()\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        \n",
    "        # 前向传播，得到模型输出\n",
    "        output = model(data)\n",
    "        # 计算损失\n",
    "        loss = criterion(output, target)\n",
    "        # 累积测试损失\n",
    "        test_loss += loss.item()\n",
    "        # 将输出概率转换为预测类别\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # 将预测与真实标签比较，得到每个样本是否预测正确的结果\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # 计算每个对象类别的测试准确率\n",
    "        for i in range(len(target)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # 计算平均测试损失\n",
    "    test_loss = test_loss/len(test_loader)\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "\n",
    "    for label in range(10):\n",
    "        print(\n",
    "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
    "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
    "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
    "    )\n",
    "\n",
    "model2 = torch.load('./model/MNIST_CollapsedNet.pth')\n",
    "\n",
    "t1 = time()\n",
    "test(model2, test_loader, criterion)\n",
    "t2 = time()\n",
    "print(\"test time=\", t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a203158d65515",
   "metadata": {},
   "source": [
    "## Encrypted Collapsed CryptoNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8013c1e34036dd3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T07:43:01.159192800Z",
     "start_time": "2024-03-21T07:43:01.131521300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#创建加密模型\n",
    "class EncCryptoNet:\n",
    "    def __init__(self, torch_nn):\n",
    "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
    "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
    "            torch_nn.conv1.kernel_size[1]\n",
    "        ).tolist()\n",
    "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
    "\n",
    "        self.fcnew_weight = torch_nn.fcnew.weight.T.data.tolist()\n",
    "        self.fcnew_bias = torch_nn.fcnew.bias.data.tolist()\n",
    "\n",
    "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
    "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
    "\n",
    "    def forward(self, enc_x, windows_nb):\n",
    "        # conv layer\n",
    "        enc_channels = []  # 存储每个通道的加密结果\n",
    "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
    "            # 执行加密的卷积操作并添加偏差\n",
    "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
    "            enc_channels.append(y)\n",
    "        # print(\"1.encx.size: \" + enc_x.size().__str__())\n",
    "        \n",
    "        # pack all channels into a single flattened vector\n",
    "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
    "        # print(\"2.encx.size: \" + enc_x.size().__str__())\n",
    "        \n",
    "        enc_x.square_()  # 对加密向量进行平方操作（激活函数）\n",
    "        # print(\"3.encx.size: \" + enc_x.size().__str__())\n",
    "        \n",
    "        # fcnew layer  \n",
    "        # print(\"windows_nb.size: \" + str(windows_nb))\n",
    "        # print(\"fcnew.size: \" + len(self.fcnew_weight).__str__())\n",
    "        enc_x = enc_x.mm(self.fcnew_weight) + self.fcnew_bias\n",
    "        enc_x.square_()\n",
    "\n",
    "        # fc2 layer\n",
    "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
    "\n",
    "        return enc_x\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "def enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride):\n",
    "    # 初始化用于监视测试损失和准确率的列表\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))  # 用于每个类别的正确预测数目\n",
    "    class_total = list(0. for i in range(10))    # 用于每个类别的样本总数\n",
    "\n",
    "    n = 0\n",
    "    for data, target in test_loader:\n",
    "        n += 1\n",
    "        if n > 50:\n",
    "            break\n",
    "        t1 = time()\n",
    "        \n",
    "        # 编码和加密  //windows_nb = 144\n",
    "        # x_enc, windows_nb = ts.im2col_encoding(\n",
    "        #     context, data.view(28, 28).tolist(), kernel_shape[0],\n",
    "        #     kernel_shape[1], stride\n",
    "        # )\n",
    "\n",
    "        # new coding\n",
    "        dat = F.pad(data, (1, 1, 1, 1))\n",
    "        x_enc, windows_nb = ts.im2col_encoding(\n",
    "            context, dat.view(30, 30).tolist(), kernel_shape[0],\n",
    "            kernel_shape[1], stride\n",
    "        )\n",
    "\n",
    "        # 加密评估\n",
    "        enc_output = enc_model(x_enc, windows_nb)\n",
    "        # 解密结果\n",
    "        output = enc_output.decrypt()\n",
    "        output = torch.tensor(output).view(1, -1)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # 将输出概率转换为预测类别\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # 将预测与真实标签比较\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # 计算每个对象类别的测试准确率\n",
    "        label = target.data[0]\n",
    "        class_correct[label] += correct.item()  \n",
    "        class_total[label] += 1\n",
    "        \n",
    "        t2 = time()\n",
    "        print(\"{} round time:{}s [{}/{}] loss:{}\".format(n, t2 - t1, n, len(test_loader),loss.item()))\n",
    "\n",
    "    # 计算并打印平均测试损失\n",
    "    test_loss = test_loss / sum(class_total)\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "    print(class_total)\n",
    "    for label in range(10):\n",
    "        print(\n",
    "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
    "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% '\n",
    "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
    "    )\n",
    "\n",
    "# 逐个加载元素\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "# 编码所需参数\n",
    "kernel_shape = model2.conv1.kernel_size\n",
    "stride = model2.conv1.stride[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cd516be8cd64ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T09:35:36.270154400Z",
     "start_time": "2024-03-21T07:43:03.934437700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 round time:84.09301710128784s [1/10000] loss:0.0021356174256652594\n",
      "2 round time:87.19123959541321s [2/10000] loss:0.02821114845573902\n",
      "3 round time:93.79601526260376s [3/10000] loss:0.0\n",
      "4 round time:94.88916230201721s [4/10000] loss:0.0009921634336933494\n",
      "5 round time:94.4293065071106s [5/10000] loss:0.3301824927330017\n",
      "6 round time:92.89857339859009s [6/10000] loss:0.0\n",
      "7 round time:93.25124335289001s [7/10000] loss:4.8993817472364753e-05\n",
      "8 round time:92.71236777305603s [8/10000] loss:0.020519010722637177\n",
      "9 round time:91.60464882850647s [9/10000] loss:0.005595141556113958\n",
      "10 round time:91.39043068885803s [10/10000] loss:0.033226463943719864\n",
      "11 round time:92.60525512695312s [11/10000] loss:0.0\n",
      "12 round time:93.21839165687561s [12/10000] loss:0.012353217229247093\n",
      "13 round time:92.95763182640076s [13/10000] loss:0.037195853888988495\n",
      "14 round time:93.9071455001831s [14/10000] loss:0.0\n",
      "15 round time:93.00287556648254s [15/10000] loss:0.2759433686733246\n",
      "16 round time:94.07708239555359s [16/10000] loss:0.06541013717651367\n",
      "17 round time:92.6325843334198s [17/10000] loss:0.008991584181785583\n",
      "18 round time:93.69908404350281s [18/10000] loss:0.0\n",
      "19 round time:92.73099279403687s [19/10000] loss:0.00114292127545923\n",
      "20 round time:91.18269801139832s [20/10000] loss:0.8049030900001526\n",
      "21 round time:93.63153386116028s [21/10000] loss:0.14331591129302979\n",
      "22 round time:93.3351788520813s [22/10000] loss:0.0002420847595203668\n",
      "23 round time:94.19492983818054s [23/10000] loss:0.005501724313944578\n",
      "24 round time:93.79252982139587s [24/10000] loss:1.3079193830490112\n",
      "25 round time:99.20601153373718s [25/10000] loss:3.4963817596435547\n",
      "26 round time:96.88380765914917s [26/10000] loss:0.0007316772826015949\n",
      "27 round time:97.59111714363098s [27/10000] loss:0.0046227253042161465\n",
      "28 round time:97.22207808494568s [28/10000] loss:0.010423151776194572\n",
      "29 round time:96.58255290985107s [29/10000] loss:0.18669316172599792\n",
      "30 round time:97.90356755256653s [30/10000] loss:0.0004881620698142797\n",
      "31 round time:97.51921153068542s [31/10000] loss:5.435795901576057e-05\n",
      "32 round time:97.18773078918457s [32/10000] loss:2.602670431137085\n",
      "33 round time:97.41258764266968s [33/10000] loss:0.0\n",
      "34 round time:94.77422261238098s [34/10000] loss:1.6212332411669195e-05\n",
      "35 round time:96.12513208389282s [35/10000] loss:0.5636194348335266\n",
      "36 round time:96.17649865150452s [36/10000] loss:0.001727875554934144\n",
      "37 round time:98.80352544784546s [37/10000] loss:20.807153701782227\n",
      "38 round time:98.89510178565979s [38/10000] loss:0.9807191491127014\n",
      "45 round time:98.47812867164612s [45/10000] loss:0.0\n",
      "46 round time:98.44288039207458s [46/10000] loss:0.0011197017738595605\n",
      "47 round time:99.30794072151184s [47/10000] loss:0.25744345784187317\n",
      "48 round time:98.30766773223877s [48/10000] loss:3.2186455882765586e-06\n",
      "49 round time:98.79371571540833s [49/10000] loss:2.145764938177308e-06\n",
      "50 round time:97.28686285018921s [50/10000] loss:0.36514759063720703\n",
      "Test Loss: 0.725871\n",
      "\n",
      "[4.0, 7.0, 4.0, 3.0, 5.0, 1.0, 9.0, 5.0, 7.0, 5.0]\n",
      "Test Accuracy of 0: 75% (3/4)\n",
      "Test Accuracy of 1: 100% (7/7)\n",
      "Test Accuracy of 2: 50% (2/4)\n",
      "Test Accuracy of 3: 100% (3/3)\n",
      "Test Accuracy of 4: 80% (4/5)\n",
      "Test Accuracy of 5: 100% (1/1)\n",
      "Test Accuracy of 6: 88% (8/9)\n",
      "Test Accuracy of 7: 100% (5/5)\n",
      "Test Accuracy of 8: 85% (6/7)\n",
      "Test Accuracy of 9: 100% (5/5)\n",
      "\n",
      "Test Accuracy (Overall): 88% (44/50)\n",
      "time= 4761.604808807373\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# 选择缩小后的测试集大小\n",
    "subset_size = 50\n",
    "\n",
    "# 生成一个指定大小的子集\n",
    "indices = torch.arange(subset_size)\n",
    "test_data_subset = Subset(test_loader, indices)\n",
    "\n",
    "# 创建DataLoader\n",
    "test_loader_subset = DataLoader(test_data_subset, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# 加密参数\n",
    "\n",
    "# 控制CKKS方案精度\n",
    "bits_scale = 26\n",
    "\n",
    "# 创建上下文\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=16384,\n",
    "    coeff_mod_bit_sizes=[40, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 40]\n",
    "    # 乘法深度：8次\n",
    ")\n",
    "# 设置全局缩放\n",
    "context.global_scale = pow(2, bits_scale)\n",
    "\n",
    "# 生成伽罗瓦密钥\n",
    "context.generate_galois_keys()\n",
    "\n",
    "\n",
    "\n",
    "# 加密评估\n",
    "model2 = torch.load('./model/MNIST_CollapsedNet.pth')\n",
    "model2.eval()\n",
    "\n",
    "t3 = time()\n",
    "enc_model = EncCryptoNet(model2)\n",
    "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride)\n",
    "t4 = time()\n",
    "print(\"time=\", t4 - t3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
